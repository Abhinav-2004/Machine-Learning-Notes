{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinav-2004/Machine-Learning-Notes/blob/main/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "30_yZ9puszfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= pd.read_csv('Data.csv')#index[row, column]\n",
        "X = dataset.iloc[: , :-1].values#locate index with this function\n",
        "Y = dataset.iloc[: , -1].values#locate index with this function\n",
        "\n",
        "print(X)\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Miq0olhEtXIM",
        "outputId": "9907488e-0c21-4fb4-8705-e3d6a8afebac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Two ways of handling missing data,\n",
        "#either delete the record (applicable if million reocrds present)\n",
        "#Or find average of that attribute and place it at missing field\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer=SimpleImputer(missing_values=np.nan, strategy='mean')#using mean of data to replace empty fields\n",
        "imputer.fit(X[:, 1:3])#using fit function to exactly map\n",
        "X[:, 1:3]= imputer.transform(X[:, 1:3])#only give numerical columns and it will fill them with mean and replace in original\n"
      ],
      "metadata": {
        "id": "QKAmk0860lwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5zn-Tly7Rx_",
        "outputId": "d182bb08-f74a-407f-ac48-3fe28acace08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OneHot Encoding is used when data is present of multiple classes not binary like yes no\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct=ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[0])], remainder='passthrough')\n",
        "\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "qh1hMya2Gn9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stjyrz6RGo_v",
        "outputId": "b5b3d532-f328-46e4-da82-9a3d8e8c9ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LabelEncoding is used to encode binary class data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n"
      ],
      "metadata": {
        "id": "6k9nq7zFGxmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9naCOzKTHDHU",
        "outputId": "8c16fb33-10cc-42a0-d082-8274a22b50dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Udemy Question where if datafield is categorical at random **position**"
      ],
      "metadata": {
        "id": "ls0dZrZXM1et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('titanic.csv')#titantic.csv was given in udemy console.\n",
        "\n",
        "\n",
        "# Identify the categorical data\n",
        "categorical_features = ['Sex', 'Embarked', 'Pclass'] #Here sex embarked and Pclass were non-numeric fields and present at unordered indexes\n",
        "\n",
        "# Implement an instance of the ColumnTransformer class\n",
        "ct = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('encoder', OneHotEncoder(), categorical_features)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "# Apply the fit_transform method on the instance of ColumnTransformer\n",
        "X = ct.fit_transform(df)\n",
        "\n",
        "# Convert the output into a NumPy array\n",
        "X = np.array(X)\n",
        "\n",
        "# Use LabelEncoder to encode binary categorical data\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['Survived'])#survived column was only categorised\n",
        "\n",
        "# Print the updated matrix of features and the dependent variable vector\n",
        "print(\"Updated matrix of features: \\n\", X)\n",
        "print(\"Updated dependent variable vector: \\n\", y)\n",
        "\n"
      ],
      "metadata": {
        "id": "sAaVlbAhNKs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=1)\n"
      ],
      "metadata": {
        "id": "rdHAGGzmY06f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1QBH5bnZrv_",
        "outputId": "ff1a27af-131a-44e2-a1fa-8cebc601cce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRbZsNAwZr3R",
        "outputId": "45a5e1df-8a95-4932-a03d-1488a8a7c34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvDGM3f3Zr_t",
        "outputId": "3b9b97f1-14aa-4ee8-f08a-b6e780877afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPB20idjZsHk",
        "outputId": "51408d16-b92e-451a-a83e-c076a12f472d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Standardisation**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "    X = (x-mean(x)) / standard deviation(x)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hSN21QL0hCO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nomalisation**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "X = (x-min(x)) / (max(x)-min(x))  \n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PDAKNh8ThsCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "#it is only applied in numeric fields not in encoded fields\n",
        "\n",
        "X_train[:, 3:]=sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:,3:] = sc.transform(X_test[:, 3:])\n"
      ],
      "metadata": {
        "id": "mLkUnYhVjX3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n",
        "print(X_test)"
      ],
      "metadata": {
        "id": "faW2jS2GmQg2",
        "outputId": "b30e08c6-8f1a-4856-c17b-0f4c7b824029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.1915918438457855 -1.0781259408412427]\n",
            " [0.0 1.0 0.0 -0.014117293757057819 -0.07013167641635407]\n",
            " [1.0 0.0 0.0 0.5667085065333239 0.6335624327104546]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.307866172742979]\n",
            " [0.0 0.0 1.0 -1.901801144700799 -1.4204636155515822]\n",
            " [1.0 0.0 0.0 1.1475343068237056 1.2326533634535488]\n",
            " [0.0 1.0 0.0 1.4379472069688966 1.5749910381638883]\n",
            " [1.0 0.0 0.0 -0.7401495441200352 -0.5646194287757336]]\n",
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#udemy question\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Wine Quality Red dataset\n",
        "df = pd.read_csv('winequality-red.csv', delimiter=';')  #when it has ; separated values in csv\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Create an instance of the StandardScaler class\n",
        "sc=StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler on the features from the training set and transform it\n",
        "X_train = sc.fit_transform(X_train)\n",
        "\n",
        "# Apply the transform to the test set\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Print the scaled training and test datasets\n",
        "print(\"Scaled training set:\\n\", X_train)\n",
        "print(\"Scaled test set:\\n\", X_test)"
      ],
      "metadata": {
        "id": "SrODOySpnQZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}